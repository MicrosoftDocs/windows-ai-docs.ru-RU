---
author: walrusmcd
title: Использование вычислительной мощности и памяти для Windows ML
description: Сведения о том, как повысить производительность приложения при использовании Windows ML.
ms.author: paulm
ms.date: 7/2/2019
ms.topic: article
keywords: windows 10, windows ai, windows ml, winml, windows machine learning
ms.localizationpriority: medium
ms.openlocfilehash: 826489a52c79b9cbcd841e7834d9bbddc664e3e6
ms.sourcegitcommit: 2139506ff12b7205283288c4bbac866ddfa812f3
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/24/2020
ms.locfileid: "80159920"
---
# <a name="windows-ml-performance-and-memory"></a>Использование вычислительной мощности и памяти для Windows ML

В этой статье показано, как управлять производительностью приложения при использовании Машинного обучения Windows.

## <a name="threading-and-concurrency"></a>Работа с потоками и параллелизм

Каждый объект, предоставляемый из среды выполнения, является *гибким*. Это означает, что к нему можно получить доступ из любого потока. См. сведения о [гибких объектах в C++/WinRT](https://docs.microsoft.com/windows/uwp/cpp-and-winrt-apis/agile-objects).

Одним из ключевых объектов, с которыми вы будете работать, является [LearningModelSession](https://docs.microsoft.com/uwp/api/windows.ai.machinelearning.learningmodelsession).  Этот объект всегда безопасно вызывать из любого потока.

* **Для сеансов GPU.** Объект блокирует и синхронизирует параллельные вызовы.  Для обеспечения параллелизма нужно создать несколько сеансов.

* **Для сеансов ЦП.** Объект не блокирует и разрешает параллельные вызовы в одном сеансе. Необходимо соблюдать осторожность при управлении собственным состоянием, буферами и объектами привязки.

Необходимо соблюдать осторожность, оценивая цель вашего сценария. Современные архитектуры GPU работают не так, как архитектуры ЦП. Например, если требуется низкая задержка, вы можете управлять распределением работы между ядрами ЦП и GPU с помощью конвейеров, а не параллелизма. Для начала ознакомьтесь со сведениями о [синхронизации с несколькими ядрами](https://docs.microsoft.com/windows/desktop/direct3d12/user-mode-heap-synchronization). Если же требуется обеспечить пропускную способность (например, одновременную обработку максимального количества образов), вы можете использовать несколько потоков и параллелизм, чтобы повысить нагрузку на ЦП.

В контексте потоков и параллелизма вы можете выполнять эксперименты и измерять временные показатели.   Производительность будет заметно меняться в зависимости от целей и сценария.

## <a name="memory-utilization"></a>Использование памяти

Каждый экземпляр [LearningModel](https://docs.microsoft.com/uwp/api/windows.ai.machinelearning.learningmodel) и [LearningModelSession](https://docs.microsoft.com/uwp/api/windows.ai.machinelearning.learningmodelsession) имеет копию модели в памяти. Если вы работаете с небольшими моделями, вы не почувствуете сложностей, но при использовании больших моделей это становится важным.

Чтобы освободить память, вызовите метод **Dispose** в модели или сеансе. Недостаточно их просто удалить, так как в некоторых языках применяется отложенная сборка мусора.

**LearningModel** сохраняет копию в памяти для поддержки создания нового сеанса. Когда вы удаляете **LearningModel**, все существующие сеансы продолжают работать.  Но теперь вы не сможете создать новый сеанс с тем же экземпляром **LearningModel**. Для больших моделей можно создать модель и сеанс, а затем удалить модель. Используя один сеанс для всех вызовов [Evaluate](https://docs.microsoft.com/uwp/api/windows.ai.machinelearning.learningmodelsession.evaluate), вы получите только одну копию большой модели в памяти.

<!--
<TODO Asynchronous calling patterns>
-->

## <a name="float16-support"></a>Поддержка Float16

Для повышения производительности и уменьшения объема памяти, занимаемой моделью, можно с помощью [WinMLTools](convert-model-winmltools.md#convert-to-floating-point-16) преобразовать модели в формат float16.

После преобразования все весовые коэффициенты и входные данные будут иметь тип float16. Ниже описано, как работать с входными и выходными данными типа float16:

* [ImageFeatureValue](https://docs.microsoft.com/uwp/api/windows.ai.machinelearning.imagefeaturevalue)
    * Рекомендуется использовать этот способ.
    * Преобразует цвета и тензоры в тип float16.
    * Поддерживает 8-битные изображения и изображения в формате bgr8, которые можно безопасно преобразовывать в тип float16 без потери данных.

* [TensorFloat](https://docs.microsoft.com/uwp/api/windows.ai.machinelearning.tensorfloat)
    * Дополнительный способ.
    * Приведение float32 к float16.
    * Для изображений такое приведение безопасно, так как bgr8 имеет малый размер и размещается в новом типе без проблем.
    * Для других типов данных операция [Bind](https://docs.microsoft.com/uwp/api/windows.ai.machinelearning.learningmodelbinding.bind) завершится сбоем, и вместо этого нужно передавать данные в [TensorFloat16Bit](https://docs.microsoft.com/uwp/api/windows.ai.machinelearning.tensorfloat16bit).

* [TensorFloat16Bit](https://docs.microsoft.com/uwp/api/windows.ai.machinelearning.tensorfloat16bit)
    * Дополнительный способ.
    * Нужно выполнить преобразование во float16 и передать входные данные в формате float32, которые будут приводиться к float16.

> [!NOTE]
> В большинстве случаев этот оператор все равно выполняет вычисления в 32-разрядном формате. Так снижается риск переполнения, а полученный результат обрезается до типа float16. Впрочем, если для оборудования заявлена поддержка float16, среда выполнения воспользуется этой возможностью.

## <a name="pre-processing-input-data"></a>Предварительная обработка входных данных

WinML автоматически выполняет некоторые действия по предварительной обработке, чтобы упростить обработку и повысить ее эффективность. Например, входящие изображения могут иметь разные цветовые форматы и размеры, часть из которых отличается от ожиданий модели. WinML преобразует такие изображения, чтобы они соответствовали требованиям, снимая эту проблему с разработчика.

Также WinML применяет весь аппаратный стек (ЦП, GPU и т. д.) для максимально эффективного преобразования под конкретное устройство и сценарий.

Но в некоторых случаях вам придется вручную преобразовывать входные данные в тензор с учетом особых ограничений. Например, если вы не хотите использовать для изображений формат [VideoFrame](https://docs.microsoft.com/uwp/api/windows.media.videoframe) или вам нужно нормализовать значения пикселей из диапазона 0–255 в диапазон 0–1. Для таких случаев можете реализовать собственное преобразование данных в тензор. Примеры таких преобразований вы найдете [здесь](https://github.com/Microsoft/Windows-Machine-Learning/tree/master/Samples/CustomTensorization).

[!INCLUDE [help](../includes/get-help.md)]
